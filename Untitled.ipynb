{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, itertools\n",
    "from dataset import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from networks import *\n",
    "from utils import *\n",
    "from glob import glob\n",
    "\n",
    "class UGATIT(object) :\n",
    "    def __init__(self, args):\n",
    "        self.light = args.light\n",
    "\n",
    "        if self.light :\n",
    "            self.model_name = 'UGATIT_light'\n",
    "        else :\n",
    "            self.model_name = 'UGATIT'\n",
    "        self.result_dir = args.result_dir\n",
    "        self.dataset = args.dataset\n",
    "        \"\"\" Weight \"\"\"\n",
    "#         self.adv_weight = args.adv_weight\n",
    "#         self.cycle_weight = args.cycle_weight\n",
    "#         self.identity_weight = args.identity_weight\n",
    "#         self.cam_weight = args.cam_weight\n",
    "\n",
    "        \"\"\" Generator \"\"\"\n",
    "        self.n_res = args.n_res\n",
    "        self.ch = args.ch\n",
    "        self.img_size = args.img_size\n",
    "        self.img_ch = args.img_ch\n",
    "\n",
    "        self.device = args.device\n",
    "#         self.benchmark_flag = args.benchmark_flag\n",
    "#         self.resume = args.resume\n",
    "\n",
    "#         if torch.backends.cudnn.enabled and self.benchmark_flag:\n",
    "#             print('set benchmark !')\n",
    "#             torch.backends.cudnn.benchmark = True\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(\"##### Information #####\")\n",
    "        print(\"# light : \", self.light)\n",
    "#         print(\"# dataset : \", self.dataset)\n",
    "#         print(\"# batch_size : \", self.batch_size)\n",
    "#         print(\"# iteration per epoch : \", self.iteration)\n",
    "\n",
    "#         print()\n",
    "\n",
    "        print(\"##### Generator #####\")\n",
    "        print(\"# residual blocks : \", self.n_res)\n",
    "\n",
    "        print()\n",
    "\n",
    "#         print(\"##### Discriminator #####\")\n",
    "#         print(\"# discriminator layer : \", self.n_dis)\n",
    "\n",
    "#         print()\n",
    "\n",
    "#         print(\"##### Weight #####\")\n",
    "#         print(\"# adv_weight : \", self.adv_weight)\n",
    "#         print(\"# cycle_weight : \", self.cycle_weight)\n",
    "#         print(\"# identity_weight : \", self.identity_weight)\n",
    "#         print(\"# cam_weight : \", self.cam_weight)\n",
    "\n",
    "    ##################################################################################\n",
    "    # Model\n",
    "    ##################################################################################\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\" DataLoader \"\"\"\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize((self.img_size + 30, self.img_size+30)),\n",
    "            transforms.RandomCrop(self.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize((self.img_size, self.img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        \"\"\" Define Generator, Discriminator \"\"\"\n",
    "        self.genA2B = ResnetGenerator(input_nc=3, output_nc=3, ngf=self.ch, n_blocks=self.n_res, img_size=self.img_size, light=self.light).to(self.device)\n",
    "\n",
    "        \"\"\" Define Loss \"\"\"\n",
    "        self.L1_loss = nn.L1Loss().to(self.device)\n",
    "        self.MSE_loss = nn.MSELoss().to(self.device)\n",
    "        self.BCE_loss = nn.BCEWithLogitsLoss().to(self.device)\n",
    "\n",
    "        \"\"\" Trainer \"\"\"\n",
    "        #self.G_optim = torch.optim.Adam(itertools.chain(self.genA2B.parameters(), self.genB2A.parameters()), lr=self.lr, betas=(0.5, 0.999), weight_decay=self.weight_decay)\n",
    "\n",
    "        \"\"\" Define Rho clipper to constraint the value of rho in AdaILN and ILN\"\"\"\n",
    "        self.Rho_clipper = RhoClipper(0, 1)\n",
    "\n",
    "    def load(self, dir, step):\n",
    "        params = torch.load(os.path.join(dir, self.dataset + '_params_%07d.pt' % step))\n",
    "        self.genA2B.load_state_dict(params['genA2B'])\n",
    "\n",
    "    def test(self, img):\n",
    "        model_list = glob(os.path.join(self.result_dir, self.dataset, 'model', '*.pt'))\n",
    "        if not len(model_list) == 0:\n",
    "            model_list.sort()\n",
    "            iter = int(model_list[-1].split('_')[-1].split('.')[0])\n",
    "            self.load(os.path.join(self.result_dir, self.dataset, 'model'), iter)\n",
    "        else:\n",
    "            return 'error'\n",
    "        self.genA2B.eval()\n",
    "        img = torch.from_numpy(img)\n",
    "        img = img.to(self.device)\n",
    "        fake_A2B, _, fake_A2B_heatmap = self.genA2B(img)\n",
    "        out = RGB2BGR(tensor2numpy(denorm(fake_A2B[0])))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test(img):\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((260, 260)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    return test_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Image.fromarray(open_cv_image)\n",
    "b = transform_test(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 260), <f4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2679\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2680\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 260), '<f4')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f6e23a6ead03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2680\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 260), <f4"
     ]
    }
   ],
   "source": [
    "Image.fromarray(b.numpy()[:, :, ::-1].copy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://images.unsplash.com/photo-1596330112119-eafc0fb76775?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=234&q=80'\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "open_cv_image = np.array(img) \n",
    "open_cv_image = open_cv_image[:, :, ::-1].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Information #####\n",
      "# light :  True\n",
      "##### Generator #####\n",
      "# residual blocks :  4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gan = UGATIT(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetGenerator(\n",
       "  (gap_fc): Linear(in_features=256, out_features=1, bias=False)\n",
       "  (gmp_fc): Linear(in_features=256, out_features=1, bias=False)\n",
       "  (conv1x1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (gamma): Linear(in_features=256, out_features=256, bias=False)\n",
       "  (beta): Linear(in_features=256, out_features=256, bias=False)\n",
       "  (UpBlock1_1): ResnetAdaILNBlock(\n",
       "    (pad1): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (norm1): adaILN()\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pad2): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (norm2): adaILN()\n",
       "  )\n",
       "  (UpBlock1_2): ResnetAdaILNBlock(\n",
       "    (pad1): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (norm1): adaILN()\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pad2): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (norm2): adaILN()\n",
       "  )\n",
       "  (UpBlock1_3): ResnetAdaILNBlock(\n",
       "    (pad1): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (norm1): adaILN()\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pad2): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (norm2): adaILN()\n",
       "  )\n",
       "  (UpBlock1_4): ResnetAdaILNBlock(\n",
       "    (pad1): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (norm1): adaILN()\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pad2): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (norm2): adaILN()\n",
       "  )\n",
       "  (DownBlock): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (10): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (13): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (14): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "    (15): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (FC): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (UpBlock2): Sequential(\n",
       "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (1): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (3): ILN()\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (6): ReflectionPad2d((1, 1, 1, 1))\n",
       "    (7): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (8): ILN()\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (11): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
       "    (12): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = glob(os.path.join(gan.result_dir, gan.dataset, 'model', '*.pt'))\n",
    "if not len(model_list) == 0:\n",
    "    model_list.sort()\n",
    "    iter = int(model_list[-1].split('_')[-1].split('.')[0])\n",
    "    gan.load(os.path.join(gan.result_dir, gan.dataset, 'model'), iter)\n",
    "else:\n",
    "    print('error')\n",
    "gan.genA2B.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://images.unsplash.com/photo-1596330112119-eafc0fb76775?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=234&q=80'\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "open_cv_image = np.array(img) \n",
    "open_cv_image = open_cv_image[:, :, ::-1].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 351, 234]), (351, 234, 3), torch.Size([351, 234, 3]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = transforms.ToTensor()(open_cv_image).unsqueeze_(0)\n",
    "a.shape, open_cv_image.shape, img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_t = torch.from_numpy(open_cv_image)\n",
    "img_t = transforms.ToTensor()(open_cv_image).unsqueeze_(0)\n",
    "img_t = img_t.to(gan.device)\n",
    "fake_A2B, _, fake_A2B_heatmap = gan.genA2B(img_t)\n",
    "out = RGB2BGR(tensor2numpy(denorm(fake_A2B[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         self.adv_weight = args.adv_weight\n",
    "#         self.cycle_weight = args.cycle_weight\n",
    "#         self.identity_weight = args.identity_weight\n",
    "#         self.cam_weight = args.cam_weight\n",
    "        \n",
    "#     parser.add_argument('--dataset', type=str, default='testing', help='dataset_name')\n",
    "\n",
    "#     parser.add_argument('--iteration', type=int, default=1000000, help='The number of training iterations')\n",
    "#     parser.add_argument('--batch_size', type=int, default=1, help='The size of batch size')\n",
    "#     parser.add_argument('--print_freq', type=int, default=1000, help='The number of image print freq')\n",
    "#     parser.add_argument('--save_freq', type=int, default=100000, help='The number of model save freq')\n",
    "#     parser.add_argument('--decay_flag', type=str2bool, default=True, help='The decay_flag')\n",
    "\n",
    "#     parser.add_argument('--lr', type=float, default=0.0001, help='The learning rate')\n",
    "#     parser.add_argument('--weight_decay', type=float, default=0.0001, help='The weight decay')\n",
    "#     parser.add_argument('--adv_weight', type=int, default=1, help='Weight for GAN')\n",
    "#     parser.add_argument('--cycle_weight', type=int, default=10, help='Weight for Cycle')\n",
    "#     parser.add_argument('--identity_weight', type=int, default=10, help='Weight for Identity')\n",
    "#     parser.add_argument('--cam_weight', type=int, default=1000, help='Weight for CAM')\n",
    "\n",
    "#     parser.add_argument('--ch', type=int, default=64, help='base channel number per layer')\n",
    "#     parser.add_argument('--n_res', type=int, default=4, help='The number of resblock')\n",
    "#     parser.add_argument('--n_dis', type=int, default=6, help='The number of discriminator layer')\n",
    "\n",
    "\n",
    "#     parser.add_argument('--result_dir', type=str, default='results', help='Directory name to save the results')\n",
    "#     parser.add_argument('--benchmark_flag', type=str2bool, default=False)\n",
    "#     parser.add_argument('--resume', type=str2bool, default=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
